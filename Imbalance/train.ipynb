{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and helper functions\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from dataprocessing import *\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import *\n",
    "from helper_functions import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import time\n",
    "import scipy.spatial.distance\n",
    "from scipy.spatial.distance import hamming\n",
    "from scipy.spatial import distance\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "# Global variables\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class Args:\n",
    "    batchsize = 100\n",
    "    model = \"mobilenet_v2\"\n",
    "    lr = 0.001\n",
    "    epochs = 200\n",
    "    dataset = \"tinyimagenet\"\n",
    "    max_noise_rate = 0.4\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset containing hard and noisy samples\n",
    "normalize = transforms.Normalize(\n",
    "      mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "data_dir = './tiny-imagenet-200'\n",
    "num_classes = 200\n",
    "trainset = TinyImageNetNoisyDatasetSpectrum(data_dir,transform =data_transforms['train'], normalize=normalize, mode='train', max_noise_rate=args.max_noise_rate)\n",
    "\n",
    "# subsampling according to class label to make dataset imbalanced\n",
    "def samples_per_class(label):\n",
    "    print(label%40)\n",
    "    if label%40 < 8:\n",
    "        return 400\n",
    "    elif label%40 < 16:\n",
    "        return 200\n",
    "    elif label%40 < 24:\n",
    "        return 100\n",
    "    elif label%40 < 32:\n",
    "        return 50\n",
    "    else:\n",
    "        return 25\n",
    "    \n",
    "subset_indices = []\n",
    "for cls in range(num_classes):\n",
    "    indices = [i for i, x in enumerate(trainset.original_label_data==cls) if x]\n",
    "    indices_sampled = random.sample(indices, samples_per_class(cls))\n",
    "    subset_indices += indices_sampled\n",
    "    \n",
    "class_dependent_hardness_dataset = torch.utils.data.Subset(trainset, subset_indices)\n",
    "trainloader = torch.utils.data.DataLoader(class_dependent_hardness_dataset, batch_size=args.batchsize,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "\n",
    "testset = TinyImageNetDataset(data_dir,transform =data_transforms['val'], normalize=normalize, mode='val')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=args.batchsize,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer definitions\n",
    "pretrained = False\n",
    "net = models.__dict__[args.model](\n",
    "        aux_logits=False,pretrained=pretrained, num_classes=num_classes) if args.model == 'inception_v3' else models.__dict__[args.model](pretrained=pretrained, num_classes=num_classes)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    # net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the hard and noisy dataset\n",
    "file_name = './results/values/hardness_via_imbalance_{}_{}_epochs_{}_lr_{}_noise_{}_deployment.pkl'.\\\n",
    "    format(args.dataset, args.model, args.epochs, args.lr, args.max_noise_rate)\n",
    "model_file_name = './checkpoint/hardness_via_imbalance_{}_{}_epochs_{}_lr_{}_noise_{}_deployment.pth'.\\\n",
    "    format(args.dataset, args.model, args.epochs, args.lr, args.max_noise_rate)\n",
    "\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickler = pickle.Pickler(f)\n",
    "    for epoch in range(args.epochs):\n",
    "        tl, ta, ta5, df_perepoch = train(epoch, net, trainloader, device, criterion, optimizer, model_name=args.model, num_classes=200)\n",
    "        tel, tea, tea5 = test(epoch, net, testloader, device, criterion)\n",
    "        scheduler.step()\n",
    "        pickler.dump([epoch, tl, ta, ta5, df_perepoch, tel, tea, tea5])\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'opt': optimizer.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "torch.save(state, model_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
