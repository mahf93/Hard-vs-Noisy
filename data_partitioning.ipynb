{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and helper functions\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from compute_metrics import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import time\n",
    "import scipy.spatial.distance\n",
    "from scipy.spatial.distance import hamming\n",
    "from scipy.spatial import distance\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "# Global variables\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class Args:\n",
    "    batchsize = 100\n",
    "    model = \"mobilenet_v2\"\n",
    "    lr = 0.001\n",
    "    epochs = 200\n",
    "    dataset = \"tinyimagenet\"\n",
    "    max_noise_rate = 0.4\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the file name and directory that the results are saved in, the file could be from any hardness types\n",
    "file_name = './results/values/imbalance/hardness_via_imbalance_{}_{}_epochs_{}_lr_{}_noise_{}_deployment.pkl'.\\\n",
    "    format(args.dataset, 'mobilenet_v2', 200, args.lr, args.max_noise_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute different metrics for each sample of the dataset\n",
    "samples_df = compute_metrics(file_name, args.epochs)    \n",
    "\n",
    "mid_training = compute_epoch_of_middle_training(file_name, 200)\n",
    "        \n",
    "samples_df['mid_feature_dist'] = samples_df.apply(lambda row: find_mid_training_scd(row['epochs-info'], 200, mid_training), axis=1)\n",
    "samples_df['end_feature_acd'] = samples_df.apply(lambda row: find_end_training_acd(row['epochs-info'], 200), axis=1)\n",
    "samples_df['end_feature_wjsd'] = samples_df.apply(lambda row: find_end_training_wjsd(row['epochs-info'], 200), axis=1)       \n",
    "samples_df['end_loss'] = samples_df.apply(lambda row: find_end_training_loss(row['epochs-info'], 200), axis=1)\n",
    "samples_df['end_conf'] = samples_df.apply(lambda row: find_end_training_conf(row['epochs-info'], 200), axis=1)\n",
    "samples_df['gray'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Final results of data partitioning for different methods: ####\n",
    "\n",
    "# baselines based on thresholding:\n",
    "easy_threshold = np.median(samples_df['end_loss'])\n",
    "Dnoisyids_thresh_loss = np.array(samples_df[samples_df['end_loss']>easy_threshold]['id'])\n",
    "Dcleanids_thresh_loss = np.array(samples_df[samples_df['end_loss']<=easy_threshold]['id']) \n",
    "\n",
    "\n",
    "easy_threshold = np.median(samples_df['acc_over_train'])\n",
    "Dnoisyids_thresh_acc = np.array(samples_df[samples_df['acc_over_train']<easy_threshold]['id'])\n",
    "Dcleanids_thresh_acc = np.array(samples_df[samples_df['acc_over_train']>=easy_threshold]['id']) \n",
    "\n",
    "\n",
    "easy_threshold = np.median(samples_df['area_under_margin'])\n",
    "Dnoisyids_thresh_aum = np.array(samples_df[samples_df['area_under_margin']<easy_threshold]['id'])\n",
    "Dcleanids_thresh_aum = np.array(samples_df[samples_df['area_under_margin']>=easy_threshold]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baselines based on 1-d GMM:\n",
    "\n",
    "clusters_here =  compute_2d_GMM(samples_df, 'end_loss', 'gray')\n",
    "samples_df['clusters_1dgmm_loss'] = clusters_here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_here =  compute_2d_GMM(samples_df, 'area_under_loss', 'gray')\n",
    "samples_df['clusters_1dgmm_aul'] = clusters_here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 0 or 1 based on the assigned clusters above\n",
    "Dnoisyids_gmm_loss = np.array(samples_df[samples_df['clusters_1dgmm_loss']==1]['id'])\n",
    "Dcleanids_gmm_loss = np.array(samples_df[samples_df['clusters_1dgmm_loss']!=1]['id'])\n",
    "\n",
    "# set 0 or 1 based on the assigned clusters above\n",
    "Dnoisyids_gmm_aul = np.array(samples_df[samples_df['clusters_1dgmm_aul']==1]['id'])\n",
    "Dcleanids_gmm_aul = np.array(samples_df[samples_df['clusters_1dgmm_aul']!=1]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baselines based on 2-d GMM:\n",
    "\n",
    "clusters_here =  compute_2d_GMM(samples_df, 'end_feature_wjsd', 'end_feature_acd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df['clusters_gmm_wjsd_acd'] = clusters_here \n",
    "Dnoisyids_gmm_wjsd_acd = np.array(samples_df[samples_df['clusters_gmm_wjsd_acd']==1]['id'])\n",
    "Dcleanids_gmm_wjsd_acd = np.array(samples_df[samples_df['clusters_gmm_wjsd_acd']==0]['id']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_here =  compute_2d_GMM_3clusters(samples_df, 'acc_over_train', 'mid_feature_scd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df['clusters_gmm_acc_scd'] = clusters_here # higher acc and lower auf is better\n",
    "Dnoisyids_gmm_acc_scd = np.array(samples_df[samples_df['clusters_gmm_acc_scd']==0]['id'])\n",
    "Dcleanids_gmm_acc_scd = np.array(samples_df[samples_df['clusters_gmm_acc_scd']!=0]['id']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which method do you want to analyze?\n",
    "Dcleanids_here = # fill this\n",
    "\n",
    "# results of the method\n",
    "print('length:', len(Dcleanids_here))\n",
    "print('correct percentage:', len(samples_df[samples_df['id'].isin(Dcleanids_here)][samples_df['label']==samples_df['original_label']])/len(Dcleanids_here))\n",
    "\n",
    "a = len(samples_df[samples_df['id'].isin(Dnoisyids_here)][samples_df['label']!=samples_df['original_label']])\n",
    "b = len(Dnoisyids_here)\n",
    "prec_n = a/b\n",
    "print('precision n:', a/b)\n",
    "\n",
    "a = len(samples_df[samples_df['id'].isin(Dnoisyids_here)][samples_df['label']!=samples_df['original_label']])\n",
    "b = len(samples_df[samples_df['label']!=samples_df['original_label']])\n",
    "recal_n = a/b\n",
    "print('recall n:', a/b)\n",
    "\n",
    "print('f1-score n:', 2*prec_n*recal_n/(prec_n+recal_n))\n",
    "\n",
    "a = len(samples_df[samples_df['id'].isin(Dcleanids_here)][(samples_df['hardness']>3)&(samples_df['label']==samples_df['original_label'])])\n",
    "b = len(Dcleanids_here)\n",
    "prec_h = a/b\n",
    "#print('precision h:', a/b)\n",
    "\n",
    "a = len(samples_df[samples_df['id'].isin(Dcleanids_here)][(samples_df['hardness']>3)&(samples_df['label']==samples_df['original_label'])])\n",
    "b = len(samples_df[samples_df['hardness']>3])\n",
    "recal_h = a/b\n",
    "print('recall h:', a/b)\n",
    "\n",
    "#print('f1-score h:', 2*prec_h*recal_h/(prec_h+recal_h))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
