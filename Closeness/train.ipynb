{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and helper functions\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from dataprocessing import *\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import *\n",
    "from helper_functions import *\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import time\n",
    "import scipy.spatial.distance\n",
    "from scipy.spatial.distance import hamming\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# set hyper parameters here\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class Args:\n",
    "    batchsize = 100\n",
    "    model = \"mobilenet_v2\"\n",
    "    lr = 0.001\n",
    "    epochs = 200\n",
    "    dataset = \"tinyimagenet\"\n",
    "    max_noise_rate = 0.4\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset containing hard and noisy samples\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "      mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = './tiny-imagenet-200'\n",
    "\n",
    "# Generating the data augmentations here\n",
    "#torch.random.manual_seed(1)\n",
    "#random.seed(1)\n",
    "transform_aug = [transforms.RandomHorizontalFlip(p=1),\n",
    "                 transforms.RandomVerticalFlip(p=1),\n",
    "                transforms.Grayscale(num_output_channels=3),\n",
    "                transforms.RandomPerspective(distortion_scale=0.5,p=1),\n",
    "                transforms.RandomPerspective(distortion_scale=0.25,p=1),\n",
    "                transforms.RandomPerspective(distortion_scale=0.75,p=1),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.RandomRotation(20),\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.RandomRotation(40),\n",
    "                transforms.RandomRotation(50),\n",
    "                transforms.GaussianBlur(3),\n",
    "                transforms.GaussianBlur(5),\n",
    "                transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "                transforms.ColorJitter(brightness=.3, hue=.5),\n",
    "                transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))\n",
    "                ]\n",
    "\n",
    "trainset = TinyImageNetAugNoisyDataset(data_dir,transform =data_transforms['train'], normalize=normalize, mode='train'\n",
    "                                  , transform_aug = transform_aug, max_noise_rate=args.max_noise_rate)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batchsize,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "\n",
    "testset = TinyImageNetDataset(data_dir,transform =data_transforms['val'], normalize=normalize, mode='val')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=args.batchsize,\n",
    "                                             shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer definitions\n",
    "pretrained = False\n",
    "net = models.__dict__[args.model](\n",
    "        aux_logits=False,pretrained=pretrained, num_classes=num_classes) if args.model == 'inception_v3' else models.__dict__[args.model](pretrained=pretrained, num_classes=num_classes)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    #net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the hard and noisy dataset\n",
    "file_name = './results/values/hardness_via_diversification_{}_{}_epochs_{}_lr_{}_noise_{}_deployment.pkl'.\\\n",
    "    format(args.dataset, args.model, args.epochs, args.lr, args.max_noise_rate)\n",
    "model_file_name = './checkpoint/hardness_via_diversification_{}_{}_epochs_{}_lr_{}_noise_{}_deployment.pth'.\\\n",
    "    format(args.dataset, args.model, args.epochs, args.lr, args.max_noise_rate)\n",
    "\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickler = pickle.Pickler(f)\n",
    "    for epoch in range(args.epochs):\n",
    "        tl, ta, ta5, df_perepoch = train(epoch, net, trainloader, device, criterion, optimizer, model_name=args.model, num_classes=200)\n",
    "        tel, tea, tea5 = test(epoch, net, testloader, device, criterion)\n",
    "        scheduler.step()\n",
    "        pickler.dump([epoch, tl, ta, ta5, df_perepoch, tel, tea, tea5])\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'opt': optimizer.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "torch.save(state, model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
